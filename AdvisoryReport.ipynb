{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advisory report\n",
    "___\n",
    "<pre>Teamname    : Submission Impossible ðŸ’¥  \n",
    "Group nr    : 32 - Company C  \n",
    "Students    : {Andrei Dragomir, Ece Doganer, MÃ¡rk Kerekes, Ariana Vargas Pastor}  \n",
    "Student nrs : {2669304,         2552855,     2696796,      2710153}  </pre>\n",
    "___\n",
    "\n",
    "#### Structure of the project:\n",
    "1. Data Exploration:\n",
    "- Data visualisation;\n",
    "- Comparisons of our company's hiree distributions as opposed to those of the other companies;\n",
    "- Hiree descriptive data distributions (based on gender, age, nationality and sports) compared to the distributions of all applicants for company C;\n",
    "- Hiree indicative data distributions compared to the distributions of all applicants for company C;\n",
    "- Data processing and cleaning.\n",
    "\n",
    "2. Modelling:\n",
    "- Model M1: Neural Network with single hidden layer and no drop-out\n",
    "    - Only use 4 out of the 8 given indicators\n",
    "    - Optional: Using a clustering algorithm based on all indicators prior to the deployment of the classification model\n",
    "- Model M2: Predictive model based on any indicators\n",
    "    - Does the model perform better than M1?\n",
    "    - Explanation of the training and testing methods\n",
    "    - Explanation of the choice of indicators\n",
    "- Model M3: Model based only on the given descriptors (age, nationality, gender and sports)\n",
    "    - Evaluate model\n",
    "    - Discuss whether using this model is ethical or not\n",
    "    \n",
    "`IMPORTANT DECISIONS: Ratio of training/test data; Model selection; Hyperparameter optimization`\n",
    "    \n",
    "3. Evaluation and advice:\n",
    "- Use _accuracy_ to test predictive models\n",
    "- Analyse one of our models (suggesting M2)\n",
    "    - test different feature combinations that result in the best accuracy rate\n",
    "- Provide advice for the HR department\n",
    "    - Should the model be used?\n",
    "    - How should the model be used?\n",
    "    - What future evaluations and calibrations needed in the future?\n",
    "    - Discuss potential risks imposed by the usage of this model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing the data set and libraries required\n",
    "\n",
    "In terms of data cleaning, we have checked for null values and observed that there are no missing entries after loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; seaborn.set()\n",
    "import statistics\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from turtle import title\n",
    "from enum import unique\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Loading dataset and checking for any possible NaN values\n",
    "recruitmentData = pd.read_csv (r'recruitmentdataset-2022-1.3.csv')\n",
    "print(recruitmentData.isnull().values.any())\n",
    "\n",
    "# print(recruitmentData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Helping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "### 1.1 Data visualisation of the general population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data frame for the dichotomous features\n",
    "dichotomousFrame = pd.DataFrame(recruitmentData, columns=['ind-debateclub', 'ind-programming_exp', 'ind-international_exp',\n",
    "                                                          'ind-entrepeneur_exp', 'ind-exact_study',  'decision'])\n",
    "\n",
    "dichotomousFrame = dichotomousFrame.rename(columns={'ind-debateclub': 'DebateExp', 'ind-programming_exp': 'ProgrammingExp', 'ind-exact_study': 'ExactStudyExp',\n",
    "                                                    'ind-international_exp': 'InternationalExp', 'ind-entrepeneur_exp': 'EntrepreneurExp', 'decision': 'Approved'})\n",
    "\n",
    "#Dichotomous features plotting in percentages\n",
    "dichotomousFrame = dichotomousFrame.apply(pd.value_counts).div(len(dichotomousFrame)).mul(100)\n",
    "dichotomousFrameFlip = dichotomousFrame.transpose()\n",
    "axis = dichotomousFrameFlip.plot.barh(figsize=(10,5), color={'#000000','#a31c1c'})\n",
    "for container in axis.containers: axis.bar_label(container)\n",
    "\n",
    "plt.title('Plot 1: Experience and hired ratios of all applicants',loc='left')\n",
    "plt.xlabel('Percentage (%)')\n",
    "plt.ylabel('Distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data frame for the multichotomous features\n",
    "multichotomousFrame = pd.DataFrame(recruitmentData, columns=['ind-languages', 'age', 'sport', 'ind-university_grade',\n",
    "                                                             'gender', 'ind-degree', 'nationality',  'company'])\n",
    "multichotomousFrame.columns = ['SpokenLanguages', 'Age', 'Sports', 'GPA', 'Genders', 'Degrees', 'Nationalities', 'Companies']\n",
    "\n",
    "#Multichotomous features plotting\n",
    "fig, axs = plt.subplots(2,4)\n",
    "fig.set_figwidth(24)\n",
    "fig.set_figheight(9)\n",
    "\n",
    "for x in range(2):\n",
    "    for y in range(4):\n",
    "        column = multichotomousFrame.iloc[:, (x * 4 + y)]\n",
    "        axs[x, y].set_title('Distribution of ' + column.name)\n",
    "        axs[x, y].hist(column, bins = column.unique().size, align='mid', orientation='horizontal', color='#a31c1c')\n",
    "fig.suptitle('Plot 2: Multichotomous qualitiy distributions of all applicants', horizontalalignment='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Visualisation of all hiree qualities for each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters used in plot creation\n",
    "numberOfGenders = recruitmentData['gender'].unique().size\n",
    "numberOfNationalities = recruitmentData['nationality'].unique().size\n",
    "numberOfSports = recruitmentData['sport'].unique().size\n",
    "\n",
    "fig, axs = plt.subplots(2,2)\n",
    "fig.suptitle('Descriptive data visualization and comparison between company C`s hirees and rest of hiree population')\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(12)\n",
    "\n",
    "#First Plot\n",
    "XSportsAxis = np.arange(numberOfSports)\n",
    "\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    sportFrame = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['sport']\n",
    "    normalizedSportCounts = sportFrame.value_counts().sort_index().divide(sportFrame.count()).multiply(100)\n",
    "    if (x == 'C'): axs[0, 0].bar(XSportsAxis + idx/numberOfSports, normalizedSportCounts, width= 1/numberOfSports, label='Company ' + str(x) + '`s hirees',color='#a31c1c')\n",
    "    else: axs[0, 0].bar(XSportsAxis + idx/numberOfSports, normalizedSportCounts, width= 1/numberOfSports, label='Company ' + str(x) + '`s hirees')\n",
    "\n",
    "axs[0, 0].set_xticks(XSportsAxis)\n",
    "axs[0, 0].set_xticklabels(recruitmentData['sport'].sort_values().unique().tolist(), rotation=45)\n",
    "axs[0, 0].set_xlabel('Sports')\n",
    "axs[0, 0].set_ylabel('Percentage (%)')\n",
    "axs[0, 0].set_title('Distribution of hiree sport choices in each company')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "#Second Plot\n",
    "XGendersAxis = np.arange(numberOfGenders)\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    genderColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['gender']\n",
    "    normalizedGenderCounts = genderColumn.value_counts().sort_index().divide(genderColumn.count()).multiply(100)\n",
    "    if (x == 'C'): axs[0, 1].bar(XGendersAxis + idx/(numberOfGenders * 4), normalizedGenderCounts, width= 1/(numberOfGenders * 4), label='Company ' + str(x) + '`s hirees',color='#a31c1c')\n",
    "    else: axs[0, 1].bar(XGendersAxis + idx/(numberOfGenders * 4), normalizedGenderCounts, width= 1/(numberOfGenders * 4), label='Company ' + str(x) + '`s hirees')\n",
    "\n",
    "axs[0, 1].set_xticks(XGendersAxis)\n",
    "axs[0, 1].set_xticklabels(recruitmentData['gender'].sort_values().unique().tolist())\n",
    "axs[0, 1].set_xlabel('Genders')\n",
    "axs[0, 1].set_ylabel('Percentage (%)')\n",
    "axs[0, 1].set_title('Distribution of hiree genders in each company')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "#Third Plot\n",
    "XNationalitiesAxis = np.arange(numberOfNationalities)\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    nationalityColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['nationality']\n",
    "    normalizedNationalityCounts = nationalityColumn.value_counts().sort_index().divide(nationalityColumn.count()).multiply(100)\n",
    "    if (x == 'C'): axs[1, 0].bar(XGendersAxis + idx/(numberOfNationalities * 4), normalizedNationalityCounts, width= 1/(numberOfNationalities * 4), label='Company ' + str(x) + '`s hirees',color='#a31c1c')\n",
    "    else: axs[1, 0].bar(XGendersAxis + idx/(numberOfNationalities * 4), normalizedNationalityCounts, width= 1/(numberOfNationalities * 4), label='Company ' + str(x) + '`s hirees')\n",
    "\n",
    "axs[1, 0].set_xticks(XNationalitiesAxis)\n",
    "axs[1, 0].set_xticklabels(recruitmentData['nationality'].sort_values().unique().tolist())\n",
    "axs[1, 0].set_xlabel('Nationalities')\n",
    "axs[1, 0].set_ylabel('Percentage (%)')\n",
    "axs[1, 0].set_title('Distribution of hiree nationalities in each company')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "#Fourth Plot\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    ageColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['age']\n",
    "    if (x == 'C'): axs[1, 1] = ageColumn.value_counts().plot(kind='density', label='Company ' + str(x) + '`s age distribution',color='#a31c1c')\n",
    "    else: axs[1, 1] = ageColumn.value_counts().plot(kind='density', label='Company ' + str(x) + '`s age distribution')\n",
    "axs[1, 1].set_xlabel('Age')\n",
    "axs[1, 1].set_ylabel('Density')\n",
    "axs[1, 1].set_title('Distribution of hiree ages in each company')\n",
    "axs[1, 1].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Hiree indicator data visualisation and analysis\n",
    "\n",
    "We start of by visualising the ratios of all indicator data. Firstly, we will compare the distribution of indicators for hirees of company C and the rest of the hiree population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,3)\n",
    "fig.suptitle('Indicative data visualization and comparison between company C`s hirees and rest of hiree population')\n",
    "fig.set_figwidth(27)\n",
    "fig.set_figheight(27)\n",
    "\n",
    "#First plot\n",
    "numberOfDegrees = recruitmentData['ind-degree'].unique().size\n",
    "XDegreeAxis = np.arange(numberOfGenders)\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    degreeColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['ind-degree']\n",
    "    normalizedDegreeCounts = degreeColumn.value_counts().sort_index().divide(degreeColumn.count()).multiply(100)\n",
    "    if (x == 'C'): axs[0, 0].bar(XDegreeAxis + idx/(numberOfDegrees * 4), normalizedDegreeCounts, width= 1/(numberOfDegrees * 4), label='Company ' + str(x) + '`s hiree degree level',color='#a31c1c')\n",
    "    else: axs[0, 0].bar(XDegreeAxis + idx/(numberOfDegrees * 4), normalizedDegreeCounts, width= 1/(numberOfDegrees * 4), label='Company ' + str(x) + '`s hiree degree level')\n",
    "\n",
    "axs[0, 0].set_xticks(XDegreeAxis)\n",
    "axs[0, 0].set_xticklabels(recruitmentData['ind-degree'].sort_values().unique().tolist())\n",
    "axs[0, 0].set_xlabel('Degrees')\n",
    "axs[0, 0].set_ylabel('Percentage (%)')\n",
    "axs[0, 0].set_title('Distribution of hiree degree levels in each company')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "#Second plot\n",
    "XBooleanAxis = np.arange(2)\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    progColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['ind-programming_exp']\n",
    "    normalizedProgCounts = progColumn.value_counts().sort_index().divide(progColumn.count()).multiply(100)\n",
    "    if (x == 'C'): axs[0, 1].bar(XBooleanAxis + idx/8, normalizedProgCounts, width= 1/8, label='Company ' + str(x) + '`s hiree programming experience ratio',color='#a31c1c')\n",
    "    else: axs[0, 1].bar(XBooleanAxis + idx/8, normalizedProgCounts, width= 1/8, label='Company ' + str(x) + '`s hiree programming experience ratio')\n",
    "\n",
    "axs[0, 1].set_xticks(XBooleanAxis)\n",
    "axs[0, 1].set_xticklabels(recruitmentData['ind-programming_exp'].sort_values().unique().tolist())\n",
    "axs[0, 1].set_xlabel('Programming experience')\n",
    "axs[0, 1].set_ylabel('Percentage (%)')\n",
    "axs[0, 1].set_title('Distribution of hirees based on their programming experience in each company')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "#Third plot\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    entrepreneurColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['ind-entrepeneur_exp']\n",
    "    normalizedEntrCounts = entrepreneurColumn.value_counts().sort_index().divide(entrepreneurColumn.count()).multiply(100)\n",
    "    if (x == 'C'): axs[0, 2].bar(XBooleanAxis + idx/8, normalizedEntrCounts, width= 1/8, label='Company ' + str(x) + '`s hiree entrepreneurship experience ratio', color='#a31c1c')\n",
    "    else: axs[0, 2].bar(XBooleanAxis + idx/8, normalizedEntrCounts, width= 1/8, label='Company ' + str(x) + '`s hiree entrepreneurship experience ratio')\n",
    "\n",
    "axs[0, 2].set_xticks(XBooleanAxis)\n",
    "axs[0, 2].set_xticklabels(recruitmentData['ind-entrepeneur_exp'].sort_values().unique().tolist())\n",
    "axs[0, 2].set_xlabel('Entrepreneurship experience')\n",
    "axs[0, 2].set_ylabel('Percentage (%)')\n",
    "axs[0, 2].set_title('Distribution of hirees based on their entrepreneurship experience in each company')\n",
    "axs[0, 2].legend()\n",
    "\n",
    "#Fourth plot\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    internationalColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['ind-international_exp']\n",
    "    normalizedInterCounts = internationalColumn.value_counts().sort_index().divide(internationalColumn.count()).multiply(100)\n",
    "    if (x == 'C'): axs[1, 0].bar(XBooleanAxis + idx/8, normalizedInterCounts, width= 1/8, label='Company ' + str(x) + '`s hiree international experience ratio', color='#a31c1c')\n",
    "    else: axs[1, 0].bar(XBooleanAxis + idx/8, normalizedInterCounts, width= 1/8, label='Company ' + str(x) + '`s hiree international experience ratio')\n",
    "\n",
    "axs[1, 0].set_xticks(XBooleanAxis)\n",
    "axs[1, 0].set_xticklabels(recruitmentData['ind-international_exp'].sort_values().unique().tolist())\n",
    "axs[1, 0].set_xlabel('International experience')\n",
    "axs[1, 0].set_ylabel('Percentage (%)')\n",
    "axs[1, 0].set_title('Distribution of hirees based on their international experience in each company')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "#Fifth plot\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    debateColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['ind-debateclub']\n",
    "    normalizedDebateCounts = debateColumn.value_counts().sort_index().divide(debateColumn.count()).multiply(100)\n",
    "    if (x == 'C'): axs[1, 1].bar(XBooleanAxis + idx/8, normalizedDebateCounts, width= 1/8, label='Company ' + str(x) + '`s hiree debating experience ratio', color='#a31c1c')\n",
    "    else: axs[1, 1].bar(XBooleanAxis + idx/8, normalizedDebateCounts, width= 1/8, label='Company ' + str(x) + '`s hiree debating experience ratio')\n",
    "\n",
    "axs[1, 1].set_xticks(XBooleanAxis)\n",
    "axs[1, 1].set_xticklabels(recruitmentData['ind-debateclub'].sort_values().unique().tolist())\n",
    "axs[1, 1].set_xlabel('Debate experience')\n",
    "axs[1, 1].set_ylabel('Percentage (%)')\n",
    "axs[1, 1].set_title('Distribution of hirees based on their debating experience in each company')\n",
    "axs[1, 1].legend()\n",
    "\n",
    "#Sixth plot\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    debateColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['ind-exact_study']\n",
    "    normalizedDebateCounts = debateColumn.value_counts().sort_index().divide(debateColumn.count()).multiply(100)\n",
    "    if (x == 'C'): axs[1, 2].bar(XBooleanAxis + idx/8, normalizedDebateCounts, width= 1/8, label='Company ' + str(x) + '`s hiree exact science background ratio', color='#a31c1c')\n",
    "    else: axs[1, 2].bar(XBooleanAxis + idx/8, normalizedDebateCounts, width= 1/8, label='Company ' + str(x) + '`s hiree exact science background ratio')\n",
    "\n",
    "axs[1, 2].set_xticks(XBooleanAxis)\n",
    "axs[1, 2].set_xticklabels(recruitmentData['ind-exact_study'].sort_values().unique().tolist())\n",
    "axs[1, 2].set_xlabel('Exact sciences')\n",
    "axs[1, 2].set_ylabel('Percentage (%)')\n",
    "axs[1, 2].set_title('Distribution of hirees based on a scientific background in each company')\n",
    "axs[1, 2].legend()\n",
    "\n",
    "#Seventh plot\n",
    "numberOfLanguages = recruitmentData['ind-languages'].unique().size\n",
    "XLanguagesAxis = np.arange(0,numberOfLanguages)\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    languageColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['ind-languages']\n",
    "    normalizedLanguageCounts = languageColumn.value_counts().sort_index().divide(languageColumn.count()).multiply(100)\n",
    "    if(normalizedLanguageCounts.index[0] != 0): normalizedLanguageCounts = pd.Series([0]).append(normalizedLanguageCounts)\n",
    "    if (x == 'C'): axs[2, 0].bar(XLanguagesAxis + idx/(numberOfLanguages*4), normalizedLanguageCounts, width= 1/(numberOfLanguages * 4), label='Company ' + str(x) + '`s hiree known languages', color='#a31c1c')\n",
    "    else: axs[2, 0].bar(XLanguagesAxis + idx/(numberOfLanguages*4), normalizedLanguageCounts, width= 1/(numberOfLanguages * 4), label='Company ' + str(x) + '`s hiree known languages')\n",
    "\n",
    "axs[2, 0].set_xticks(XLanguagesAxis)\n",
    "axs[2, 0].set_xticklabels(recruitmentData['ind-languages'].sort_values().unique().tolist())\n",
    "axs[2, 0].set_xlabel('No. of languages spoken')\n",
    "axs[2, 0].set_ylabel('Percentage (%)')\n",
    "axs[2, 0].set_title('Distribution of hiree known languages in each company')\n",
    "axs[2, 0].legend()\n",
    "\n",
    "axs[2, 1].set_visible(False)\n",
    "\n",
    "#Eigth plot\n",
    "for idx, x in enumerate(recruitmentData['company'].unique()):\n",
    "    gradeColumn = recruitmentData.query(\"decision and company == '\" + str(x) + \"'\")['ind-university_grade']\n",
    "    if (x == 'C'): axs[2, 2] = gradeColumn.value_counts().plot(kind='density', label='Company ' + str(x) + '`s grade distribution', color='#a31c1c')\n",
    "    else: axs[2, 2] = gradeColumn.value_counts().plot(kind='density', label='Company ' + str(x) + '`s grade distribution')\n",
    "axs[2, 2].set_xlabel('Grade')\n",
    "axs[2, 2].set_ylabel('Density')\n",
    "axs[2, 2].set_title('Distribution of hiree grades in each company')\n",
    "axs[2, 2].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicator analysis based on the plots above:\n",
    "\n",
    "- In the first graph we can observe that for our company, the majority of the hirees have finished a masters degree (70% of the candidates) but this is the case for all the other companies as well.\n",
    "\n",
    "- Based on the second, third, fifth and sixth graphs we can conclude that the majority of company C's hirees do not have any programming experience, any entrepreneurship experience, any debate experience and the majority also does not come from a scientific background.\n",
    "\n",
    "- One thing to note (based on the fourth graph) is that the hirees of our company are evenly distributed between people that have had international experience and people that did not.\n",
    "\n",
    "- Based on the eigth graph we can conclude that our company's hirees know around 2-3 other languages.\n",
    "\n",
    "- Lastly, in terms of university grades, we can observe that the hirees of our company have an average of scores close to 62/100 with the maximum grade achieved being 77/100 and the lowest grade being 51/100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Data cleaning and preparation as well as evaluating highest correlating parameters\n",
    "\n",
    "In this section we will evaluate the features that we have visualized in the plotting above, make some assumptions and test them in terms of data meaningfulness.\n",
    "These assumption will be used when building a model in the hopes of achieving a fair discrete alternative to our categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus the dataset to our company\n",
    "dataSet = recruitmentData.query(\"company == 'C'\")\n",
    "dataSetC = pd.DataFrame(dataSet, columns=[\n",
    "    'age',\n",
    "    'gender',\n",
    "    'nationality',\n",
    "    'sport',\n",
    "    'ind-university_grade',\n",
    "    'ind-debateclub',\n",
    "    'ind-programming_exp',\n",
    "    'ind-international_exp',\n",
    "    'ind-entrepeneur_exp',\n",
    "    'ind-languages',\n",
    "    'ind-exact_study',\n",
    "    'ind-degree',\n",
    "    'decision'\n",
    "])\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "\n",
    "# Convert the following numerical labels from interger to float\n",
    "conversions = {\n",
    "    'age' : float,\n",
    "    'ind-languages' : float,\n",
    "    'ind-university_grade' : float\n",
    "}\n",
    "dataSetC = dataSetC.astype(conversions)\n",
    "    \n",
    "# Label Encoder conversion\n",
    "dataSetC['decision'] = labelEncoder.fit_transform(dataSetC['decision'])\n",
    "dataSetC['ind-debateclub'] = labelEncoder.fit_transform(dataSetC['ind-debateclub'])\n",
    "dataSetC['ind-entrepeneur_exp'] = labelEncoder.fit_transform(dataSetC['ind-entrepeneur_exp'])\n",
    "dataSetC['ind-exact_study'] = labelEncoder.fit_transform(dataSetC['ind-exact_study'])\n",
    "dataSetC['ind-programming_exp'] = labelEncoder.fit_transform(dataSetC['ind-programming_exp'])\n",
    "dataSetC['ind-international_exp'] = labelEncoder.fit_transform(dataSetC['ind-international_exp'])    \n",
    "\n",
    "# One Hot Encoding conversion for gender, sport and degree\n",
    "dataSetC = pd.get_dummies(dataSetC)\n",
    "\n",
    "# Scale our data \n",
    "scaler = StandardScaler()\n",
    "dataSetCNew = pd.DataFrame(scaler.fit_transform(dataSetC), columns= dataSetC.columns)\n",
    "\n",
    "# Evaluating correlations in order to potentially find good combinations of features\n",
    "corr = dataSetCNew.corr()\n",
    "plt.figure(figsize=(10,10))\n",
    "seaborn.heatmap(corr, mask=np.zeros_like(corr), cmap=seaborn.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True)\n",
    "plt.show()            \n",
    "ranking = corr['decision']\n",
    "ranking = ranking.sort_values()\n",
    "ranking.name = \"Ranking of the predictive power of indicators\"\n",
    "print(ranking)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models\n",
    "\n",
    "### 2.1 Model 1: Neural Network with single hidden layer and no drop-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare configuration for cross validation test harness\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "results = pd.DataFrame(columns=['model','fit_time','score_time','test_accuracy', 'test_precision', 'test_recall', 'test_f1', 'features'])\n",
    "models = []\n",
    "inputChoices = [pd.DataFrame(dataSetCNew, columns=['ind-languages', 'ind-degree_phd', 'ind-degree_master', 'ind-international_exp']),\n",
    "\t\t\t\tdataSetCNew.filter(like='ind').sample(n=4,axis='columns'),\n",
    "\t\t\t\tdataSetCNew.filter(like='ind').sample(n=3,axis='columns'),\n",
    "\t\t\t\tdataSetCNew.filter(like='ind').sample(n=5,axis='columns')]\n",
    "target = dataSetC['decision']\n",
    "\n",
    "#Setting hyperparameters and evaluation outputs\n",
    "seed = 7\n",
    "splits = 10\n",
    "epochs = 300\n",
    "scores = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "#Training model for each input variation\n",
    "for idx, input in enumerate(inputChoices):\t\n",
    "\n",
    "\tkfold = model_selection.KFold(n_splits=splits, random_state=seed, shuffle=True)\n",
    "\tmodel = Sequential()\n",
    "\tdataLogger = CSVLogger('epochAnalysis.csv', separator=\",\", append=True)\n",
    "\t#input layer\n",
    "\tmodel.add(Dense(6, kernel_initializer='uniform', activation = 'relu', input_dim = input.columns.size))\n",
    "\n",
    "\t#output layer\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation = 'sigmoid'))\n",
    "\n",
    "\t#run model M1\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\tkeras_clf = KerasClassifier(model = model, optimizer=\"adam\", epochs=epochs, verbose=0, callbacks=[dataLogger])\n",
    "\tcv_results = model_selection.cross_validate(keras_clf, input, target, cv=kfold, scoring=scores)\n",
    "\n",
    "\t#Saving dataFrame of epoch based results for plotting\n",
    "\tnew_row = {'model': int(idx + 1), \n",
    "\t\t\t'fit_time' : cv_results['fit_time'].mean(),\n",
    "\t\t\t'score_time' : cv_results['score_time'].mean(),\n",
    "\t\t\t'test_accuracy' : cv_results['test_accuracy'].mean(),\n",
    "\t\t\t'test_precision' : cv_results['test_precision'].mean(),\n",
    "\t\t\t'test_recall' : cv_results['test_recall'].mean(),\n",
    "\t\t\t'test_f1' : cv_results['test_f1'].mean(),\n",
    "\t\t\t'features' : ', '.join(input.columns)}\n",
    "\tresults = results.append(new_row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up figure for result plotting\n",
    "fig, axs = plt.subplots(2,2)\n",
    "axs = axs.ravel()\n",
    "fig.suptitle('Training metric changes (over epochs) of M1 based on different feature choices')\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "\n",
    "#Plotting epoch accuracy and loss\n",
    "epochData = pd.read_csv (r'epochAnalysis.csv')\n",
    "sectionStart = 0\n",
    "\n",
    "for index in range(0, len(inputChoices), 1):\n",
    "    #Select the logs only of one set of inputs\n",
    "    sectionOfInterest = epochData.loc[(index * epochs * splits):((index + 1) * epochs * splits)]\n",
    "\n",
    "    #Prepare container for data compression\n",
    "    averagedFrame = pd.DataFrame(columns=epochData.columns)\n",
    "    for idx, epoch in enumerate(sectionOfInterest['epoch'].unique()):\n",
    "        oneEpoch = sectionOfInterest.query('epoch == %i' % epoch)\n",
    "        averagedFrame = averagedFrame.append({'epoch' : epoch,\n",
    "                                            'accuracy' : oneEpoch['accuracy'].mean(),\n",
    "                                            'loss' : oneEpoch['loss'].mean()\n",
    "                                            }, ignore_index=True)\n",
    "    \n",
    "    axs[index].set_title('Feature set: %s' % ', '.join(inputChoices[index].columns))\n",
    "    axs[index].plot(averagedFrame['accuracy'], label='M1 %i accuracy' % index)\n",
    "    axs[index].plot(averagedFrame['loss'], label='M1 %i loss' % index)\n",
    "    axs[index].legend()\n",
    "    print(averagedFrame)\n",
    "\n",
    "# Clear epoch data for new run\n",
    "f = open(\"epochAnalysis.csv\", \"w\")\n",
    "f.truncate()\n",
    "f.close()\n",
    "\n",
    "\n",
    "# XResultsAxis = np.arange(len(plottingFrame.columns))\n",
    "# for idx, x in enumerate(results['model']):\n",
    "#     row = plottingFrame.iloc[[idx]].values\n",
    "#     print(row)\n",
    "#     plt.bar(XResultsAxis + idx/(XResultsAxis * 4), row, width= 1/(XResultsAxis * 4), label='Model' + str(x) + ' results')\n",
    "# plottingFrame = results.drop(['model','features', 'fit_time', 'score_time'], axis=1)\n",
    "# print(plottingFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model 3: Neural Network with single hidden layer and no drop-out on descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare configuration for cross validation test harness\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "results = pd.DataFrame(columns=['model','fit_time','score_time','test_accuracy', 'test_precision', 'test_recall', 'test_f1', 'features'])\n",
    "models = []\n",
    "inputChoices = [pd.DataFrame(dataSetCNew, columns=['sport_Tennis', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sport_Running', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sport_Swimming', \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sport_Chess',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sport_Football',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sport_Golf',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sport_Cricket',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'sport_Rugby',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'gender_female',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'gender_other',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'gender_male',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'nationality_German',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'nationality_Dutch',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'nationality_Belgian',\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t'age']),\n",
    "\t\t\t\t# dataSetCNew.filter(like='ind').sample(n=4,axis='columns'),\n",
    "\t\t\t\t# dataSetCNew.filter(like='ind').sample(n=3,axis='columns'),\n",
    "\t\t\t\t# dataSetCNew.filter(like='ind').sample(n=5,axis='columns')\n",
    "\t\t\t\t]\n",
    "target = dataSetC['decision']\n",
    "\n",
    "#Setting hyperparameters and evaluation outputs\n",
    "seed = 7\n",
    "splits = 10\n",
    "epochs = 300\n",
    "scores = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "#Training model for each input variation\n",
    "for idx, input in enumerate(inputChoices):\t\n",
    "\n",
    "\tkfold = model_selection.KFold(n_splits=splits, random_state=seed, shuffle=True)\n",
    "\tmodel = Sequential()\n",
    "\tdataLogger = CSVLogger('epochAnalysis.csv', separator=\",\", append=True)\n",
    "\t#input layer\n",
    "\tmodel.add(Dense(6, kernel_initializer='uniform', activation = 'relu', input_dim = input.columns.size))\n",
    "\n",
    "\t#output layer\n",
    "\tmodel.add(Dense(1, kernel_initializer='uniform', activation = 'sigmoid'))\n",
    "\n",
    "\t#run model M1\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\tkeras_clf = KerasClassifier(model = model, optimizer=\"adam\", epochs=epochs, verbose=0, callbacks=[dataLogger])\n",
    "\tcv_results = model_selection.cross_validate(keras_clf, input, target, cv=kfold, scoring=scores)\n",
    "\n",
    "\t#Saving dataFrame of epoch based results for plotting\n",
    "\tnew_row = {'model': int(idx + 1), \n",
    "\t\t\t'fit_time' : cv_results['fit_time'].mean(),\n",
    "\t\t\t'score_time' : cv_results['score_time'].mean(),\n",
    "\t\t\t'test_accuracy' : cv_results['test_accuracy'].mean(),\n",
    "\t\t\t'test_precision' : cv_results['test_precision'].mean(),\n",
    "\t\t\t'test_recall' : cv_results['test_recall'].mean(),\n",
    "\t\t\t'test_f1' : cv_results['test_f1'].mean(),\n",
    "\t\t\t'features' : ', '.join(input.columns)}\n",
    "\tresults = results.append(new_row, ignore_index=True)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da9fddbb10c13d74a17e4662a940d3abf594ba4b4ea9e3627d1a27856bb85182"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
